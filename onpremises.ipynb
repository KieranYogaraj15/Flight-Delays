{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predicting Airplane Delays\n",
    "\n",
    "The goals of this notebook are:\n",
    "- Process and create a dataset from downloaded ZIP files\n",
    "- Exploratory data analysis (EDA)\n",
    "- Establish a baseline model and improve it\n",
    "\n",
    "## Introduction to business scenario\n",
    "You work for a travel booking website that is working to improve the customer experience for flights that were delayed. The company wants to create a feature to let customers know if the flight will be delayed due to weather when the customers are booking the flight to or from the busiest airports for domestic travel in the US. \n",
    "\n",
    "You are tasked with solving part of this problem by leveraging machine learning to identify whether the flight will be delayed due to weather. You have been given access to the a dataset of on-time performance of domestic flights operated by large air carriers. You can use this data to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.\n",
    "\n",
    "### Dataset\n",
    "The provided dataset contains scheduled and actual departure and arrival times reported by certified US air carriers that account for at least 1 percent of domestic scheduled passenger revenues. The data was collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS). The dataset contains date, time, origin, destination, airline, distance, and delay status of flights for flights between 2014 and 2018.\n",
    "The data are in 60 compressed files, where each file contains a CSV for the flight details in a month for the five years (from 2014 - 2018). The data can be downloaded from this link: [https://ucstaff-my.sharepoint.com/:f:/g/personal/ibrahim_radwan_canberra_edu_au/Er0nVreXmihEmtMz5qC5kVIB81-ugSusExPYdcyQTglfLg?e=bNO312]. Please download the data files and place them on a relative path. Dataset(s) used in this assignment were compiled by the Office of Airline Information, Bureau of Transportation Statistics (BTS), Airline On-Time Performance Data, available with the following link: [https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Problem formulation and data collection\n",
    "\n",
    "Start this project off by writing a few sentences below that summarize the business problem and the business goal you're trying to achieve in this scenario. Include a business metric you would like your team to aspire toward. With that information defined, clearly write out the machine learning problem statement. Finally, add a comment or two about the type of machine learning this represents. \n",
    "\n",
    "\n",
    "### 1. Determine if and why ML is an appropriate solution to deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to predict whether a flight will be delayed or not from data requires statistical methods to make the predictions. The commonly used statistical methods to make predictions today are machine learning models. Even after deploying a model, the model can be continuously trained with new data. A Machine Learning model's ability to predict will continuously improve when being continuously trained on new data. A trained ML is easy to deploy into a website where it can easily predict if a future flight will be delayed based on the current data of the future flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formulate the business problem, success metrics, and desired ML output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a feature in the travel booking website that will let customers know if a flight will be delayed or not, due to the weather, while they are booking a flight on the largest airlines from the busiest airports in the US. This will allow customers to know if the delay will impact their ability to be on time at the destination for an event. With this knowledge, customers can book a flight with a different airline with a similar departure and arrival times for the same destination. Another case is if many airlines will have delayed flights within the same departure and arrival times for the same destination, then the customers will arrange alternative methods of getting to their destination, which will result in the travel booking company missing out potential sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business metric is for the same customers to return in the future to book flights with the travel booking company because they can trust the website has the best information when booking a flight. Also the potential to get new customers to book their flights with the company. All of this will drive up revenue for the company. The success metrics will be a high accuracy of the ML model being able to correctly predict if a flight will be delayed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired ML output would be a high accuracy of a model's ability to correctly predict whether a flight will be delayed or not. The ML is expected to output 0s or 1s where a 0 indicates a flight will not be delayed and a 1 indicates a flight will be delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify the type of ML problem you’re dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of Machine Learning problem is Binary Classification because there are two classes to predict, whether a flight will be delayed or not delayed. ML problem is also supervised because the dataset contains a target variable. Only ML models capable of performing classification can be used such as logistic regression and extreme gradient boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Now that we have decided where to focus our energy, let's set things up so you can start working on solving the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib2 import Path\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data preprocessing and visualization  \n",
    "In this data preprocessing phase, you should take the opportunity to explore and visualize your data to better understand it. First, import the necessary libraries and read the data into a Pandas dataframe. After that, explore your data. Look for the shape of the dataset and explore your columns and the types of columns you're working with (numerical, categorical). Consider performing basic statistics on the features to get a sense of feature means and ranges. Take a close look at your target column and determine its distribution.\n",
    "\n",
    "### Specific questions to consider\n",
    "1. What can you deduce from the basic statistics you ran on the features? \n",
    "\n",
    "2. What can you deduce from the distributions of the target classes?\n",
    "\n",
    "3. Is there anything else you deduced from exploring the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by bringing in the dataset from an Amazon S3 public bucket to this notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the files\n",
    "\n",
    "# <note: make them all relative, absolute path is not accepted>\n",
    "zip_path = 'data_compressed/'\n",
    "base_path = os.getcwd() + '/'\n",
    "csv_base_path = 'csv_data'\n",
    "\n",
    "!mkdir -p {csv_base_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 zip files\n"
     ]
    }
   ],
   "source": [
    "# How many zip files do we have? write a code to answer it.\n",
    "zip_files = os.listdir(zip_path)\n",
    "print(f\"There are {len(zip_files)} zip files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract CSV files from ZIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def zip2csv(zipFile_name , file_path):\n",
    "    \"\"\"\n",
    "    Extract csv from zip files\n",
    "    zipFile_name: name of the zip file\n",
    "    file_path : name of the folder to store csv\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with ZipFile(zipFile_name, 'r') as z: \n",
    "            print(f'Extracting {zipFile_name} ') \n",
    "            z.extractall(path=file_path) \n",
    "    except:\n",
    "        print(f'zip2csv failed for {zipFile_name}')\n",
    "\n",
    "for file in zip_files:\n",
    "    zip2csv((zip_path+file), csv_base_path)\n",
    "\n",
    "print(\"Files Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many csv files have we extracted? write a code to answer it.\n",
    "csv_files = [file for file in os.listdir(csv_base_path) if \"csv\" in file] #Exclude the readme file\n",
    "print(f\"There are {len(csv_files)} csv files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the CSV file, read the HTML file from the extracted folder. This HTML file includes the background and more information on the features included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=os.path.relpath(f\"{csv_base_path}/readme.html\"), width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load sample CSV\n",
    "\n",
    "Before combining all the CSV files, get a sense of the data from a single CSV file. Using Pandas, read the `On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2018_9.csv` file first. You can use the Python built-in `read_csv` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(\"csv_data/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2018_9.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print the row and column length in the dataset, and print the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = df_temp.shape\n",
    "print(f'Rows and columns in one csv file is {df_shape}')\n",
    "print(df_temp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print the first 10 rows of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print all the columns in the dataset. Use `<dataframe>.columns` to view the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in df_temp.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print all the columns in the dataset that contain the word 'Del'. This will help you see how many columns have delay data in them.\n",
    "\n",
    "**Hint**: You can use a Python list comprehension to include values that pass certain `if` statement criteria.\n",
    "\n",
    "For example: `[x for x in [1,2,3,4,5] if x > 2]`  \n",
    "\n",
    "**Hint**: You can use the `in` keyword ([documentation](https://www.w3schools.com/python/ref_keyword_in.asp)) to check if the value is in a list or not. \n",
    "\n",
    "For example: `5 in [1,2,3,4,5]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df_temp.columns if \"Del\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some more questions to help you find out more about your dataset.\n",
    "\n",
    "**Questions**   \n",
    "1. How many rows and columns does the dataset have?   \n",
    "2. How many years are included in the dataset?   \n",
    "3. What is the date range for the dataset?   \n",
    "4. Which airlines are included in the dataset?   \n",
    "5. Which origin and destination airports are covered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to answer above questions, complete the following code\n",
    "print(\"The #rows and #columns are \", df_temp.shape[0] , \" and \", df_temp.shape[1])\n",
    "print(\"The years in this dataset are: \", df_temp[\"Year\"].unique())\n",
    "print(\"The months covered in this dataset are: \", df_temp[\"Month\"].unique())\n",
    "print(\"The date range for data is :\" , min(df_temp[\"DayofMonth\"]), \" to \", max(df_temp[\"DayofMonth\"]))\n",
    "print(\"The airlines covered in this dataset are: \", list(df_temp[\"Reporting_Airline\"].unique()))\n",
    "print(\"The Origin airports covered are: \", list(df_temp[\"Origin\"].unique()))\n",
    "print(\"The Destination airports covered are: \", list(df_temp[\"Dest\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the count of all the origin and destination airports?\n",
    "\n",
    "**Hint**: You can use the Pandas `values_count` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)) to find out the values for each airport using the columns `Origin` and `Dest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame({'Origin':df_temp[\"Origin\"].value_counts(), 'Destination':df_temp[\"Dest\"].value_counts()})\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print the top 15 origin and destination airports based on number of flights in the dataset.\n",
    "\n",
    "**Hint**: You can use the Pandas `sort_values` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sort_values(by=[\"Origin\",\"Destination\"],ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Given all the information about a flight trip, can you predict if it would be delayed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only if there is a history of flight delays for a particular origin, destination, airline or certain times in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assume you are traveling from San Francisco to Los Angeles on a work trip. You want to have an ideas if your flight will be delayed, given a set of features, so that you can manage your reservations in Los Angeles better. How many features from this dataset would you know before your flight?\n",
    "\n",
    "Columns such as `DepDelay`, `ArrDelay`, `CarrierDelay`, `WeatherDelay`, `NASDelay`, `SecurityDelay`, `LateAircraftDelay`, and `DivArrDelay` contain information about a delay. But this delay could have occured at the origin or destination. If there were a sudden weather delay 10 minutes before landing, this data would not be helpful in managing your Los Angeles reservations.\n",
    "\n",
    "So to simplify the problem statement, consider the following columns to predict an arrival delay:<br>\n",
    "\n",
    "`Year`, `Quarter`, `Month`, `DayofMonth`, `DayOfWeek`, `FlightDate`, `Reporting_Airline`, `Origin`, `OriginState`, `Dest`, `DestState`, `CRSDepTime`, `DepDelayMinutes`, `DepartureDelayGroups`, `Cancelled`, `Diverted`, `Distance`, `DistanceGroup`, `ArrDelay`, `ArrDelayMinutes`, `ArrDel15`, `AirTime`\n",
    "\n",
    "You will also filter the source and destination airports to be:\n",
    "- Top airports: ATL, ORD, DFW, DEN, CLT, LAX, IAH, PHX, SFO\n",
    "- Top 5 airlines: UA, OO, WN, AA, DL\n",
    "\n",
    "This should help in reducing the size of data across the CSV files to be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all CSV files\n",
    "\n",
    "**Hint**:  \n",
    "First, create an empy dataframe that you will use to copy your individual dataframes from each file. Then, for each file in the `csv_files` list:\n",
    "\n",
    "1. Read the CSV file into a dataframe  \n",
    "2. Filter the columns based on the `filter_cols` variable\n",
    "\n",
    "```\n",
    "        columns = ['col1', 'col2']\n",
    "        df_filter = df[columns]\n",
    "```\n",
    "\n",
    "3. Keep only the subset_vals in each of the subset_cols. Use the `isin` Pandas function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html)) to check if the `val` is in the dataframe column and then choose the rows that include it.\n",
    "\n",
    "```\n",
    "        df_eg[df_eg['col1'].isin('5')]\n",
    "```\n",
    "\n",
    "4. Concatenate the dataframe with the empty dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(csv_files, filter_cols, subset_cols, subset_vals, file_name):\n",
    "    \"\"\"\n",
    "    Combine csv files into one Data Frame\n",
    "    csv_files: list of csv file paths\n",
    "    filter_cols: list of columns to filter\n",
    "    subset_cols: list of columns to subset rows\n",
    "    subset_vals: list of list of values to subset rows\n",
    "    \"\"\"\n",
    "    # Create an empty dataframe\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    #Loop over the csv file paths\n",
    "    for csv in csv_files:\n",
    "        #Read each csv file into a dataframe\n",
    "        df = pd.read_csv(csv_base_path + \"/\" + csv)\n",
    "        #Filter columns\n",
    "        df = df[filter_cols]\n",
    "        #Filter rows with specific values in specific columns\n",
    "        df = df[df[subset_cols[0]].isin(subset_vals[0])] #Origin\n",
    "        df = df[df[subset_cols[1]].isin(subset_vals[1])] #Dest\n",
    "        df = df[df[subset_cols[2]].isin(subset_vals[2])] #Reporting_Airline\n",
    "        #Concatenate dataframe with empty dataframe\n",
    "        combined_df = pd.concat([combined_df,df], ignore_index=True)\n",
    "        #Print the csv file name that was concatenated to the empty dataframe\n",
    "        print(csv)\n",
    "        \n",
    "    #Create csv file for the combined dataframes\n",
    "    combined_df.to_csv(file_name)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols is the list of columns to predict Arrival Delay \n",
    "cols = ['Year','Quarter','Month','DayofMonth','DayOfWeek','FlightDate',\n",
    "        'Reporting_Airline','Origin','OriginState','Dest','DestState',\n",
    "        'CRSDepTime','Cancelled','Diverted','Distance','DistanceGroup',\n",
    "        'ArrDelay','ArrDelayMinutes','ArrDel15','AirTime']\n",
    "\n",
    "subset_cols = ['Origin', 'Dest', 'Reporting_Airline']\n",
    "\n",
    "# subset_vals is a list collection of the top origin and destination airports and top 5 airlines\n",
    "subset_vals = [['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'IAH', 'PHX', 'SFO'], \n",
    "               ['ATL', 'ORD', 'DFW', 'DEN', 'CLT', 'LAX', 'IAH', 'PHX', 'SFO'], \n",
    "               ['UA', 'OO', 'WN', 'AA', 'DL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to merge all the different files into a single file that you can read easily. \n",
    "\n",
    "**Note**: This will take 5-7 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "combined_csv_filename = f\"{base_path}combined_files.csv\"\n",
    "\n",
    "csv_files = [file for file in os.listdir(csv_base_path) if \"csv\" in file] #Exclude the readme file\n",
    "combine_csv(csv_files, cols, subset_cols, subset_vals, combined_csv_filename)\n",
    "\n",
    "print(f'csv\\'s merged in {round((time.time() - start)/60,2)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "\n",
    "Load the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_filename = f\"{base_path}combined_files.csv\"\n",
    "data = pd.read_csv(combined_csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 5 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>...</th>\n",
       "      <th>DestState</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DistanceGroup</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>AirTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-10-03</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-10-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "0           0  2014        4     10           1          3  2014-10-01   \n",
       "1           1  2014        4     10           2          4  2014-10-02   \n",
       "2           2  2014        4     10           3          5  2014-10-03   \n",
       "3           3  2014        4     10           4          6  2014-10-04   \n",
       "4           4  2014        4     10           5          7  2014-10-05   \n",
       "\n",
       "  Reporting_Airline Origin OriginState  ... DestState CRSDepTime  Cancelled  \\\n",
       "0                AA    DFW          TX  ...        CA        755        0.0   \n",
       "1                AA    DFW          TX  ...        CA        755        0.0   \n",
       "2                AA    DFW          TX  ...        CA        755        0.0   \n",
       "3                AA    DFW          TX  ...        CA        755        0.0   \n",
       "4                AA    DFW          TX  ...        CA        755        0.0   \n",
       "\n",
       "   Diverted  Distance  DistanceGroup  ArrDelay  ArrDelayMinutes  ArrDel15  \\\n",
       "0       0.0    1464.0              6      -9.0              0.0       0.0   \n",
       "1       0.0    1464.0              6      40.0             40.0       1.0   \n",
       "2       0.0    1464.0              6       9.0              9.0       0.0   \n",
       "3       0.0    1464.0              6     -16.0              0.0       0.0   \n",
       "4       0.0    1464.0              6      -8.0              0.0       0.0   \n",
       "\n",
       "   AirTime  \n",
       "0    195.0  \n",
       "1    199.0  \n",
       "2    196.0  \n",
       "3    195.0  \n",
       "4    192.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some more questions to help you find out more about your dataset.\n",
    "\n",
    "**Questions**   \n",
    "1. How many rows and columns does the dataset have?   \n",
    "2. How many years are included in the dataset?   \n",
    "3. What is the date range for the dataset?   \n",
    "4. Which airlines are included in the dataset?   \n",
    "5. Which origin and destination airports are covered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to answer above questions, complete the following code\n",
    "print(\"The #rows and #columns are \", data.shape[0], \" and \", data.shape[1])\n",
    "print(\"The years in this dataset are: \", list(data[\"Year\"].unique()))\n",
    "print(\"The months covered in this dataset are: \", sorted(list(data[\"Month\"].unique())))\n",
    "print(\"The date range for data is :\" , min(data[\"DayofMonth\"]), \" to \", max(data[\"DayofMonth\"]))\n",
    "print(\"The airlines covered in this dataset are: \", list(data[\"Reporting_Airline\"].unique()))\n",
    "print(\"The Origin airports covered are: \", list(data[\"Origin\"].unique()))\n",
    "print(\"The Destination airports covered are: \", list(data[\"Dest\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our **target column : is_delay** (1 - if arrival time delayed more than 15 minutes, 0 - otherwise). Use the `rename` method to rename the column from `ArrDel15` to `is_delay`.\n",
    "\n",
    "**Hint**: You can use the Pandas `rename` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)).\n",
    "\n",
    "For example:\n",
    "```\n",
    "df.rename(columns={'col1':'column1'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"ArrDel15\":\"is_delay\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for nulls across columns. You can use the `isnull()` function ([documentation](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.isnull.html)).\n",
    "\n",
    "**Hint**: `isnull()` detects whether the particular value is null or not and gives you a boolean (True or False) in its place. Use the `sum(axis=0)` function to sum up the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               0\n",
       "Year                     0\n",
       "Quarter                  0\n",
       "Month                    0\n",
       "DayofMonth               0\n",
       "DayOfWeek                0\n",
       "FlightDate               0\n",
       "Reporting_Airline        0\n",
       "Origin                   0\n",
       "OriginState              0\n",
       "Dest                     0\n",
       "DestState                0\n",
       "CRSDepTime               0\n",
       "Cancelled                0\n",
       "Diverted                 0\n",
       "Distance                 0\n",
       "DistanceGroup            0\n",
       "ArrDelay             22540\n",
       "ArrDelayMinutes      22540\n",
       "is_delay             22540\n",
       "AirTime              22540\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrival delay details and airtime are missing for 22540 out of 1658130 rows, which is 1.3%. You can either remove or impute these rows. The documentation does not mention anything about missing rows.\n",
    "\n",
    "**Hint**: Use the `~` operator to choose the values that aren't null from the `isnull()` output.\n",
    "\n",
    "For example:\n",
    "```\n",
    "null_eg = df_eg[~df_eg['column_name'].isnull()]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with nulls\n",
    "data = data[~data['ArrDelay'].isnull()]\n",
    "data = data[~data['ArrDelayMinutes'].isnull()]\n",
    "data = data[~data['is_delay'].isnull()]\n",
    "data = data[~data['AirTime'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "Year                 0\n",
       "Quarter              0\n",
       "Month                0\n",
       "DayofMonth           0\n",
       "DayOfWeek            0\n",
       "FlightDate           0\n",
       "Reporting_Airline    0\n",
       "Origin               0\n",
       "OriginState          0\n",
       "Dest                 0\n",
       "DestState            0\n",
       "CRSDepTime           0\n",
       "Cancelled            0\n",
       "Diverted             0\n",
       "Distance             0\n",
       "DistanceGroup        0\n",
       "ArrDelay             0\n",
       "ArrDelayMinutes      0\n",
       "is_delay             0\n",
       "AirTime              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the hour of the day in 24-hour time format from CRSDepTime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the values in CRSDepTime have 4 digits\n",
    "time_str = data[\"CRSDepTime\"].astype(\"str\")\n",
    "\n",
    "new_time = []\n",
    "for time in time_str:\n",
    "    if len(time) == 1:\n",
    "        time = \"000\" + time\n",
    "    if len(time) == 2:\n",
    "        time = \"00\" + time\n",
    "    if len(time) == 3:\n",
    "        time = \"0\" + time\n",
    "    new_time.append(time)\n",
    "    \n",
    "#Only interested in the hours\n",
    "hours = [time[:2] for time in new_time]\n",
    "\n",
    "#Convert hours into 24 hour time\n",
    "#hour_24 = [datetime.strptime(hour, \"%H\").time() for hour in hours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DepHourofDay'] = hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The ML problem statement**\n",
    "- Given a set of features, can you predict if a flight is going to be delayed more than 15 minutes?\n",
    "- Because the target variable takes only 0/1 value, you could use a classification algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "#### Check class delay vs. no delay\n",
    "\n",
    "**Hint**: Use a `groupby` plot ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)) with a `bar` plot ([documentation](https://matplotlib.org/tutorials/introductory/pyplot.html)) to plot the frequency vs. distribution of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(data.groupby(\"is_delay\").size()/len(data)).plot(kind='bar')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What can you deduce from the bar plot about the ratio of delay vs. no delay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0 class frequency is 0.8 while the 1 class frequency is 0.2. This means the 0 class if four times larger than the 1 class. The ratio of delay vs no delay is 1:4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**: \n",
    "\n",
    "- Which months have the most delays?\n",
    "- What time of the day has the most delays?\n",
    "- What day of the week has the most delays?\n",
    "- Which airline has the most delays?\n",
    "- Which origin and destination airports have the most delays?\n",
    "- Is flight distance a factor in the delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_columns = ['Month', 'DepHourofDay', 'DayOfWeek', 'Reporting_Airline', 'Origin', 'Dest']\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20,20), squeeze=False)\n",
    "# fig.autofmt_xdate(rotation=90)\n",
    "\n",
    "for idx, column in enumerate(viz_columns):\n",
    "    ax = axes[idx//2, idx%2]\n",
    "    temp = data.groupby(column)['is_delay'].value_counts(normalize=True).rename('percentage').\\\n",
    "    mul(100).reset_index().sort_values(column)\n",
    "    sns.barplot(x=column, y=\"percentage\", hue=\"is_delay\", data=temp, ax=ax)\n",
    "    plt.ylabel('% delay/no-delay')\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot( x=\"is_delay\", y=\"Distance\", data=data, fit_reg=False, hue='is_delay', legend=False)\n",
    "plt.legend(loc='center')\n",
    "plt.xlabel('is_delay')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which months have the most delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "June, July and August have the most delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What time of the day has the most delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20:00:00 or 8pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What day of the week has the most delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The day with the most delays is 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which airline has the most delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which origin and destination airports have the most delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin = ORD. Destination = SFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is flight distance a factor in the delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight distance seems to have no factor in a flight's delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Look at all the columns and what their specific types are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek',\n",
       "       'FlightDate', 'Reporting_Airline', 'Origin', 'OriginState', 'Dest',\n",
       "       'DestState', 'CRSDepTime', 'Cancelled', 'Diverted', 'Distance',\n",
       "       'DistanceGroup', 'ArrDelay', 'ArrDelayMinutes', 'is_delay', 'AirTime',\n",
       "       'DepHourofDay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             int64\n",
       "Year                   int64\n",
       "Quarter                int64\n",
       "Month                  int64\n",
       "DayofMonth             int64\n",
       "DayOfWeek              int64\n",
       "FlightDate            object\n",
       "Reporting_Airline     object\n",
       "Origin                object\n",
       "OriginState           object\n",
       "Dest                  object\n",
       "DestState             object\n",
       "CRSDepTime             int64\n",
       "Cancelled            float64\n",
       "Diverted             float64\n",
       "Distance             float64\n",
       "DistanceGroup          int64\n",
       "ArrDelay             float64\n",
       "ArrDelayMinutes      float64\n",
       "is_delay             float64\n",
       "AirTime              float64\n",
       "DepHourofDay          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the required columns:\n",
    "- Date is redundant, because you have Year, Quarter, Month, DayofMonth, and DayOfWeek to describe the date.\n",
    "- Use Origin and Dest codes instead of OriginState and DestState.\n",
    "- Because you are just classifying whether the flight is delayed or not, you don't need TotalDelayMinutes, DepDelayMinutes, and ArrDelayMinutes.\n",
    "\n",
    "Treat DepHourofDay as a categorical variable because it doesn't have any quantitative relation with the target.\n",
    "- If you had to do a one-hot encoding of it, it would result in 23 more columns.\n",
    "- Other alternatives to handling categorical variables include hash encoding, regularized mean encoding, and bucketizing the values, among others.\n",
    "- Just split into buckets here.\n",
    "\n",
    "**Hint**: To change a column type to category, use the `astype` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = data.copy()\n",
    "data = data[[ 'is_delay', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "       'Reporting_Airline', 'Origin', 'Dest','Distance','DepHourofDay']]\n",
    "categorical_columns  = ['Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "       'Reporting_Airline', 'Origin', 'Dest', 'DepHourofDay']\n",
    "for c in categorical_columns:\n",
    "    data[c] = data[c].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use one-hot encoding, use the Pandas `get_dummies` function for the categorical columns that you selected above. Then, you can concatenate those generated features to your original dataset using the Pandas `concat` function. For encoding categorical variables, you can also use *dummy encoding* by using a keyword `drop_first=True`. For more information on dummy encoding, see https://en.wikiversity.org/wiki/Dummy_variable_(statistics).\n",
    "\n",
    "For example:\n",
    "```\n",
    "pd.get_dummies(df[['column1','columns2']], drop_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\n",
    "data = pd.concat([data, data_dummies], axis = 1)\n",
    "data.drop(categorical_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of the dataset and the new columnms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of the dataset\n",
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_delay', 'Distance', 'Quarter_2', 'Quarter_3', 'Quarter_4',\n",
       "       'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7',\n",
       "       'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12',\n",
       "       'DayofMonth_2', 'DayofMonth_3', 'DayofMonth_4', 'DayofMonth_5',\n",
       "       'DayofMonth_6', 'DayofMonth_7', 'DayofMonth_8', 'DayofMonth_9',\n",
       "       'DayofMonth_10', 'DayofMonth_11', 'DayofMonth_12', 'DayofMonth_13',\n",
       "       'DayofMonth_14', 'DayofMonth_15', 'DayofMonth_16', 'DayofMonth_17',\n",
       "       'DayofMonth_18', 'DayofMonth_19', 'DayofMonth_20', 'DayofMonth_21',\n",
       "       'DayofMonth_22', 'DayofMonth_23', 'DayofMonth_24', 'DayofMonth_25',\n",
       "       'DayofMonth_26', 'DayofMonth_27', 'DayofMonth_28', 'DayofMonth_29',\n",
       "       'DayofMonth_30', 'DayofMonth_31', 'DayOfWeek_2', 'DayOfWeek_3',\n",
       "       'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7',\n",
       "       'Reporting_Airline_DL', 'Reporting_Airline_OO', 'Reporting_Airline_UA',\n",
       "       'Reporting_Airline_WN', 'Origin_CLT', 'Origin_DEN', 'Origin_DFW',\n",
       "       'Origin_IAH', 'Origin_LAX', 'Origin_ORD', 'Origin_PHX', 'Origin_SFO',\n",
       "       'Dest_CLT', 'Dest_DEN', 'Dest_DFW', 'Dest_IAH', 'Dest_LAX', 'Dest_ORD',\n",
       "       'Dest_PHX', 'Dest_SFO', 'DepHourofDay_01', 'DepHourofDay_02',\n",
       "       'DepHourofDay_04', 'DepHourofDay_05', 'DepHourofDay_06',\n",
       "       'DepHourofDay_07', 'DepHourofDay_08', 'DepHourofDay_09',\n",
       "       'DepHourofDay_10', 'DepHourofDay_11', 'DepHourofDay_12',\n",
       "       'DepHourofDay_13', 'DepHourofDay_14', 'DepHourofDay_15',\n",
       "       'DepHourofDay_16', 'DepHourofDay_17', 'DepHourofDay_18',\n",
       "       'DepHourofDay_19', 'DepHourofDay_20', 'DepHourofDay_21',\n",
       "       'DepHourofDay_22', 'DepHourofDay_23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The new columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Answer:** \n",
    "```\n",
    "Index(['Distance', 'is_delay', 'Quarter_2', 'Quarter_3', 'Quarter_4',\n",
    "       'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7',\n",
    "       'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12',\n",
    "       'DayofMonth_2', 'DayofMonth_3', 'DayofMonth_4', 'DayofMonth_5',\n",
    "       'DayofMonth_6', 'DayofMonth_7', 'DayofMonth_8', 'DayofMonth_9',\n",
    "       'DayofMonth_10', 'DayofMonth_11', 'DayofMonth_12', 'DayofMonth_13',\n",
    "       'DayofMonth_14', 'DayofMonth_15', 'DayofMonth_16', 'DayofMonth_17',\n",
    "       'DayofMonth_18', 'DayofMonth_19', 'DayofMonth_20', 'DayofMonth_21',\n",
    "       'DayofMonth_22', 'DayofMonth_23', 'DayofMonth_24', 'DayofMonth_25',\n",
    "       'DayofMonth_26', 'DayofMonth_27', 'DayofMonth_28', 'DayofMonth_29',\n",
    "       'DayofMonth_30', 'DayofMonth_31', 'DayOfWeek_2', 'DayOfWeek_3',\n",
    "       'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7',\n",
    "       'Reporting_Airline_DL', 'Reporting_Airline_OO', 'Reporting_Airline_UA',\n",
    "       'Reporting_Airline_WN', 'Origin_CLT', 'Origin_DEN', 'Origin_DFW',\n",
    "       'Origin_IAH', 'Origin_LAX', 'Origin_ORD', 'Origin_PHX', 'Origin_SFO',\n",
    "       'Dest_CLT', 'Dest_DEN', 'Dest_DFW', 'Dest_IAH', 'Dest_LAX', 'Dest_ORD',\n",
    "       'Dest_PHX', 'Dest_SFO'],\n",
    "      dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to do model training. Before splitting the data, rename the column `is_delay` to `target`.\n",
    "\n",
    "**Hint**: You can use the Pandas `rename` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {\"is_delay\":\"target\"}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to Save the combined csv file (combined_csv_v1.csv) to your local computer\n",
    "# note this combined file will be used in part B\n",
    "data.to_csv(base_path + \"combined_csv_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model training and evaluation\n",
    "\n",
    "1. Split the data into `train_data`, and `test_data` using `sklearn.model_selection.train_test_split`.  \n",
    "2. Build a logistic regression model for the data, where training data is 80%, and test data is 20%.\n",
    "\n",
    "Use the following cells to complete these steps. Insert and delete cells where needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target variable\n",
    "X = data.drop(columns=[\"target\"])\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=0)\n",
    "\n",
    "#Train the model\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict with the trained model\n",
    "predictions = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "In this section, you'll evaluate your trained model on test data and report on the following metrics:\n",
    "* Confusion Matrix plot\n",
    "* Plot the ROC\n",
    "* Report statistics such as Accuracy, Percision, Recall, Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a plot of the confusion matrix, and various scoring metrics, create a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    cm = confusion_matrix(test_labels, target_predicted, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "    disp.plot()\n",
    "    plt.grid(False) #Remove white lines in plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc(test_labels, target_predicted):\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the confusion matrix, call the `plot_confusion_matrix` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print statistics and plot an ROC curve, call the `plot_roc` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key questions to consider:\n",
    "1. How does your model's performance on the test set compare to the training set? What can you deduce from this comparison? \n",
    "\n",
    "2. Are there obvious differences between the outcomes of metrics like accuracy, precision, and recall? If so, why might you be seeing those differences? \n",
    "\n",
    "3. Is the outcome for the metric(s) you consider most important sufficient for what you need from a business standpoint? If not, what are some things you might change in your next iteration (in the feature engineering section, which is coming up next)? \n",
    "\n",
    "Use the cells below to answer these and other questions. Insert and delete cells where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does your model's performance on the test set compare to the training set? What can you deduce from this comparison?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the trained model on the training dataset\n",
    "predictions = log_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's performance on the test and train sets are the same. The confusion matrix (ratio of True Positive, True Negative, False Positive and False Negative), ROC plot, precision, recall, f1-score and the accuracy are the same for both sets. The model is completely biased towards the non-delayed class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are there obvious differences between the outcomes of metrics like accuracy, precision, and recall? If so, why might you be seeing those differences?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no differences between the outcomes of the metrics in the train and test sets. This is because the model is predicting most flights in both sets as non-delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the outcome for the metric(s) you consider most important, sufficient for what you need from a business standpoint? If not, what are some things you might change in your next iteration (in the feature engineering section, which is coming up next)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics outcomes are not sufficient for the business problem. 79% is a good value for accuracy, however, the other metrics show that the model is not performing well. because they indicate the model is not performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next iteration, standardise the numerical features so that they are all in the same scale and have a normal distribution. Remove outliers in the numerical features. Impute missing values instead of removing rows that contain the missing values. See if there is a relationship between the numerical features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question**: What can you summarize from the confusion matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does well in predicting the non-delayed class. The plot shows that most flights in both sets were predicted as non-delayed. This means the model is biased towards the non-delayed class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Deployment\n",
    "\n",
    "1. In this step you are required to push your source code and requirements file to a GitLab repository without the data files. Please use the Git commands to complete this task\n",
    "2- Create a “readme.md” markdown file that describes the code of this repository and how to run it and what the user would expect if got the code running.\n",
    "\n",
    "In the cell below provide the link of the pushed repository on your GitLab account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gitlab.com/Kieran.Yogaraj/final-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Feature engineering\n",
    "\n",
    "You've now gone through one iteration of training and evaluating your model. Given that the outcome you reached for your model the first time probably wasn't sufficient for solving your business problem, what are some things you could change about your data to possibly improve model performance?\n",
    "\n",
    "### Key questions to consider:\n",
    "1. How might the balance of your two main classes (delay and no delay) impact model performance?\n",
    "2. Do you have any features that are correlated?\n",
    "3. Are there feature reduction techniques you could perform at this stage that might have a positive impact on model performance? \n",
    "4. Can you think of adding some more data/datasets?\n",
    "4. After performing some feature engineering, how does your model performance compare to the first iteration?\n",
    "\n",
    "Use the cells below to perform specific feature engineering techniques (per the questions above) that you think could improve your model performance. Insert and delete cells where needed.\n",
    "\n",
    "\n",
    "Before you start, think about why the precision and recall are around 80% while the accuracy is 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add more features\n",
    "\n",
    "1. Holidays\n",
    "2. Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the list of holidays from 2014 to 2018 is known, you can create an indicator variable **is_holiday** to mark these.\n",
    "The hypothesis is that airplane delays could be higher during holidays compared to the rest of the days. Add a boolean variable `is_holiday` that includes the holidays for the years 2014-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: http://www.calendarpedia.com/holidays/federal-holidays-2014.html\n",
    "\n",
    "holidays_14 = ['2014-01-01',  '2014-01-20', '2014-02-17', '2014-05-26', '2014-07-04', '2014-09-01', '2014-10-13', '2014-11-11', '2014-11-27', '2014-12-25' ] \n",
    "holidays_15 = ['2015-01-01',  '2015-01-19', '2015-02-16', '2015-05-25', '2015-06-03', '2015-07-04', '2015-09-07', '2015-10-12', '2015-11-11', '2015-11-26', '2015-12-25'] \n",
    "holidays_16 = ['2016-01-01',  '2016-01-18', '2016-02-15', '2016-05-30', '2016-07-04', '2016-09-05', '2016-10-10', '2016-11-11', '2016-11-24', '2016-12-25', '2016-12-26']\n",
    "holidays_17 = ['2017-01-02', '2017-01-16', '2017-02-20', '2017-05-29' , '2017-07-04', '2017-09-04' ,'2017-10-09', '2017-11-10', '2017-11-23', '2017-12-25']\n",
    "holidays_18 = ['2018-01-01', '2018-01-15', '2018-02-19', '2018-05-28' , '2018-07-04', '2018-09-03' ,'2018-10-08', '2018-11-12','2018-11-22', '2018-12-25']\n",
    "holidays = holidays_14+ holidays_15+ holidays_16 + holidays_17+ holidays_18\n",
    "\n",
    "### Add indicator variable for holidays\n",
    "is_holiday = []\n",
    "\n",
    "for date in data_orig[\"FlightDate\"]:\n",
    "    count = 0\n",
    "    for holiday in holidays:\n",
    "        if date == holiday:\n",
    "            is_holiday.append(True)\n",
    "            break\n",
    "        count += 1\n",
    "    #If flight date isn't a holiday\n",
    "    if count == len(holidays):\n",
    "        is_holiday.append(False)\n",
    "\n",
    "data_orig['is_holiday'] = is_holiday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather data was fetched from https://www.ncei.noaa.gov/access/services/data/v1?dataset=daily-summaries&stations=USW00023174,USW00012960,USW00003017,USW00094846,USW00013874,USW00023234,USW00003927,USW00023183,USW00013881&dataTypes=AWND,PRCP,SNOW,SNWD,TAVG,TMIN,TMAX&startDate=2014-01-01&endDate=2018-12-31.\n",
    "<br>\n",
    "\n",
    "This dataset has information on wind speed, precipitation, snow, and temperature for cities by their airport codes.\n",
    "\n",
    "**Question**: Could bad weather due to rains, heavy winds, or snow lead to airplane delay? Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download data from the link above and place it into the data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import weather data prepared for the airport codes in our dataset. Use the stations and airports below for the analysis, and create a new column called `airport` that maps the weather station to the airport name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"daily-summaries.csv\")\n",
    "station = ['USW00023174','USW00012960','USW00003017','USW00094846',\n",
    "           'USW00013874','USW00023234','USW00003927','USW00023183','USW00013881'] \n",
    "airports = ['LAX', 'IAH', 'DEN', 'ORD', 'ATL', 'SFO', 'DFW', 'PHX', 'CLT']\n",
    "\n",
    "### Map weather stations to airport code\n",
    "station_map = {'USW00023174':'LAX', 'USW00012960':'IAH','USW00003017':'DEN','USW00094846':'ORD',\n",
    "               'USW00013874':'ATL','USW00023234':'SFO','USW00003927':'DFW','USW00023183':'PHX','USW00013881':'CLT'}\n",
    "station_copy = weather[\"STATION\"].copy()\n",
    "weather['airport'] = station_copy.replace(station_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another column called `MONTH` from the `DATE` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather['MONTH'] = weather[\"DATE\"].apply(lambda x: x.split('-')[1])\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output\n",
    "```\n",
    "  STATION     DATE      AWND PRCP SNOW SNWD TAVG TMAX  TMIN airport MONTH\n",
    "0 USW00023174 2014-01-01 16   0   NaN  NaN 131.0 178.0 78.0  LAX    01\n",
    "1 USW00023174 2014-01-02 22   0   NaN  NaN 159.0 256.0 100.0 LAX    01\n",
    "2 USW00023174 2014-01-03 17   0   NaN  NaN 140.0 178.0 83.0  LAX    01\n",
    "3 USW00023174 2014-01-04 18   0   NaN  NaN 136.0 183.0 100.0 LAX    01\n",
    "4 USW00023174 2014-01-05 18   0   NaN  NaN 151.0 244.0 83.0  LAX    01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze and handle the `SNOW` and `SNWD` columns for missing values using `fillna()`. Use the `isna()` function to check the missing values for all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather.SNOW.fillna(0, inplace=True)\n",
    "weather.SNWD.fillna(0, inplace=True)\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Print the index of the rows that have missing values for TAVG, TMAX, TMIN.\n",
    "\n",
    "**Hint**: Use the `isna()` function to find the rows that are missing, and then use the list on the idx variable to get the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([i for i in range(len(weather))])\n",
    "TAVG_idx = idx[weather[\"TAVG\"].isna()]\n",
    "TMAX_idx = idx[weather[\"TMAX\"].isna()]\n",
    "TMIN_idx = idx[weather[\"TMIN\"].isna()]\n",
    "TAVG_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output\n",
    "\n",
    "```\n",
    "array([ 3956,  3957,  3958,  3959,  3960,  3961,  3962,  3963,  3964,\n",
    "        3965,  3966,  3967,  3968,  3969,  3970,  3971,  3972,  3973,\n",
    "        3974,  3975,  3976,  3977,  3978,  3979,  3980,  3981,  3982,\n",
    "        3983,  3984,  3985,  4017,  4018,  4019,  4020,  4021,  4022,\n",
    "        4023,  4024,  4025,  4026,  4027,  4028,  4029,  4030,  4031,\n",
    "        4032,  4033,  4034,  4035,  4036,  4037,  4038,  4039,  4040,\n",
    "        4041,  4042,  4043,  4044,  4045,  4046,  4047, 13420])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can replace the missing TAVG, TMAX, and TMIN with the average value for a particular station/airport. Because the consecutive rows of TAVG_idx are missing, replacing with a previous value would not be possible. Instead, replace it with the mean. Use the `groupby` function to aggregate the variables with a mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_impute = weather.groupby([\"MONTH\",\"STATION\"]).agg({'TAVG':'mean','TMAX':'mean', 'TMIN':'mean'}).reset_index()\n",
    "weather_impute.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the mean data with the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the yesterday's data\n",
    "weather = pd.merge(weather, weather_impute,  how='left', left_on=['MONTH','STATION'], right_on = ['MONTH','STATION'])\\\n",
    ".rename(columns = {'TAVG_y':'TAVG_AVG',\n",
    "                   'TMAX_y':'TMAX_AVG', \n",
    "                   'TMIN_y':'TMIN_AVG',\n",
    "                   'TAVG_x':'TAVG',\n",
    "                   'TMAX_x':'TMAX', \n",
    "                   'TMIN_x':'TMIN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.TAVG[TAVG_idx] = weather.TAVG_AVG[TAVG_idx]\n",
    "weather.TMAX[TMAX_idx] = weather.TMAX_AVG[TMAX_idx]\n",
    "weather.TMIN[TMIN_idx] = weather.TMIN_AVG[TMIN_idx]\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `STATION,MONTH,TAVG_AVG,TMAX_AVG,TMIN_AVG,TMAX,TMIN,SNWD` from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['STATION','MONTH','TAVG_AVG', 'TMAX_AVG', 'TMIN_AVG', 'TMAX' ,'TMIN', 'SNWD'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the origin and destination weather conditions to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add origin weather conditions\n",
    "data_orig = pd.merge(data_orig, weather,  how='left', left_on=['FlightDate','Origin'], right_on = ['DATE','airport'])\\\n",
    ".rename(columns = {'AWND':'AWND_O','PRCP':'PRCP_O', 'TAVG':'TAVG_O', 'SNOW': 'SNOW_O'})\\\n",
    ".drop(columns=['DATE','airport'])\n",
    "\n",
    "### Add destination weather conditions\n",
    "data_orig = pd.merge(data_orig, weather,  how='left', left_on=['FlightDate','Dest'], right_on = ['DATE','airport'])\\\n",
    ".rename(columns = {'AWND':'AWND_D','PRCP':'PRCP_D', 'TAVG':'TAVG_D', 'SNOW': 'SNOW_D'})\\\n",
    ".drop(columns=['DATE','airport'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is always a good practice to check nulls/NAs after joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the categorical data into numerical data using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_orig.copy()\n",
    "data = data[['is_delay', 'Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "       'Reporting_Airline', 'Origin', 'Dest','Distance','DepHourofDay','is_holiday', 'AWND_O', 'PRCP_O',\n",
    "       'TAVG_O', 'AWND_D', 'PRCP_D', 'TAVG_D', 'SNOW_O', 'SNOW_D']]\n",
    "\n",
    "\n",
    "categorical_columns  = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    "       'Reporting_Airline', 'Origin', 'Dest', 'is_holiday']\n",
    "for c in categorical_columns:\n",
    "    data[c] = data[c].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you have any features that are correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all the numerical variables\n",
    "numerical = [col for col in data.columns if data[col].dtype != \"category\"]\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap\n",
    "corr = data[numerical].corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some correlation between TAVG_D and TAVG_O. All the features have very little to no correlation with the is_delay variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\n",
    "data = pd.concat([data, data_dummies], axis = 1)\n",
    "data.drop(categorical_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code\n",
    "\n",
    "```\n",
    "data_dummies = pd.get_dummies(data[['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'Reporting_Airline', 'Origin', 'Dest', 'is_holiday']], drop_first=True)\n",
    "data = pd.concat([data, data_dummies], axis = 1)\n",
    "categorical_columns.remove('is_delay')\n",
    "data.drop(categorical_columns,axis=1, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output\n",
    "\n",
    "```\n",
    "Index(['Distance', 'DepHourofDay', 'is_delay', 'AWND_O', 'PRCP_O', 'TAVG_O',\n",
    "       'AWND_D', 'PRCP_D', 'TAVG_D', 'SNOW_O', 'SNOW_D', 'Year_2015',\n",
    "       'Year_2016', 'Year_2017', 'Year_2018', 'Quarter_2', 'Quarter_3',\n",
    "       'Quarter_4', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6',\n",
    "       'Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12',\n",
    "       'DayofMonth_2', 'DayofMonth_3', 'DayofMonth_4', 'DayofMonth_5',\n",
    "       'DayofMonth_6', 'DayofMonth_7', 'DayofMonth_8', 'DayofMonth_9',\n",
    "       'DayofMonth_10', 'DayofMonth_11', 'DayofMonth_12', 'DayofMonth_13',\n",
    "       'DayofMonth_14', 'DayofMonth_15', 'DayofMonth_16', 'DayofMonth_17',\n",
    "       'DayofMonth_18', 'DayofMonth_19', 'DayofMonth_20', 'DayofMonth_21',\n",
    "       'DayofMonth_22', 'DayofMonth_23', 'DayofMonth_24', 'DayofMonth_25',\n",
    "       'DayofMonth_26', 'DayofMonth_27', 'DayofMonth_28', 'DayofMonth_29',\n",
    "       'DayofMonth_30', 'DayofMonth_31', 'DayOfWeek_2', 'DayOfWeek_3',\n",
    "       'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7',\n",
    "       'Reporting_Airline_DL', 'Reporting_Airline_OO', 'Reporting_Airline_UA',\n",
    "       'Reporting_Airline_WN', 'Origin_CLT', 'Origin_DEN', 'Origin_DFW',\n",
    "       'Origin_IAH', 'Origin_LAX', 'Origin_ORD', 'Origin_PHX', 'Origin_SFO',\n",
    "       'Dest_CLT', 'Dest_DEN', 'Dest_DFW', 'Dest_IAH', 'Dest_LAX', 'Dest_ORD',\n",
    "       'Dest_PHX', 'Dest_SFO', 'is_holiday_1'],\n",
    "      dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `is_delay` column to `target` again. Use the same code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {\"is_delay\":\"target\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to Save the new combined csv file (combined_csv_v2.csv) to your local computer\n",
    "# note this combined file will be also used in part B\n",
    "data.to_csv(base_path + \"combined_csv_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there feature reduction techniques you could perform at this stage that might have a positive impact on model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle Component Analysis will be used to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise the dataset\n",
    "features = data.drop(columns=[\"target\"])\n",
    "target = data[\"target\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit df to scaler\n",
    "scaler.fit(features)\n",
    "\n",
    "#Scale data\n",
    "scaled_data = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with components that explain 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "\n",
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Principle Components with the Target variable\n",
    "pca_data = pd.DataFrame(pca_data)\n",
    "data = pd.concat([pca_data, target], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training and testing sets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target variable\n",
    "X = data.drop(columns=[\"target\"])\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New baseline classifier\n",
    "\n",
    "Now, see if these new features add any predictive power to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate another logistic regression model\n",
    "classifier2 = LogisticRegression(random_state=0)\n",
    "\n",
    "#Train the model\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict with the trained model\n",
    "predictions = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the evaluaion as you have done with the previous model and plot/show the same metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: did you notice a difference by adding the extra data on the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the weather data decreased the Precision and Recall of both non-delayed and delayed classes. The f1-score increased for the delayed class. However, the accuracy remained the same. The ROC in the ROC plot has slightly shifted upwards. In the confuion matrix, the number of flights predicted as delayed and the number of False Positives have increased, this is why the Precision and Recall scores decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Using Tableau\n",
    "\n",
    "Use Tableau to load the combined_csv_v2.csv file and build a dashboard that show your understanding of the data and business problem. \n",
    "### what to do:\n",
    "1. Load the data into Tableau and build the dashboard\n",
    "2. Share the dashboard on your Tableau public account \n",
    "3. Copy the link of the shared dashboard below\n",
    "\n",
    "Note: The dashboard needs to be self explainable to others, so make it simple and add only the features that you feel heighlight the main question(s) of the prblem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://public.tableau.com/app/profile/kieran.yogaraj/viz/FlightDelays_16675333885410/FlightsDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've now gone through at least a couple iterations of training and evaluating your model. It's time to wrap up this project and reflect on what you've learned and what types of steps you might take moving forward (assuming you had more time). Use the cell below to answer some of these and other relevant questions:\n",
    "\n",
    "1. Does your model performance meet your business goal? If not, what are some things you'd like to do differently if you had more time for tuning?\n",
    "2. To what extent did your model improve as you made changes to your dataset? What types of techniques did you employ throughout this project that you felt yielded the greatest improvements in your model?\n",
    "3. What were some of the biggest challenges you encountered throughout this project?\n",
    "4. What were the three most important things you learned about machine learning while completing this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does your model performance meet your business goal? If not, what are some things you'd like to do differently if you had more time for tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not meet the business goal because the model is really biased in predicting almost all flights as being non-delayed, which includes flights that should be predicted as delayed. What I would do differently is use cross validation to stratify and to find the optimal values for the model's parameters. I would also remove outliers and standardise the numerical features. I would use a more complex classification ML model such as Random Forest, XGBoost or Artifical Neural Neural. Impute the missing values TAVG, TMIN and TMAX with the median instead of the mean because the median is robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To what extent did your model improve as you made changes to your dataset? What types of techniques did you employ throughout this project that you felt yielded the greatest improvements in your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extent the model improved is increasing the number of flights in the testing dataset that were correctly predicted as delayed and also increased the number of False Positive. Also, the Precision and Recall of the delayed class decreased while the F1-Score increased. The technique I used that had the greatest improvement is Principal Component Analysis to do dimensionality reduction to obtain components that explain the variance at 95%. This had the greatest decrease in Precision and Recall of the delayed class decreased and had the greatest increase in the F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were some of the biggest challenges you encountered throughout this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the csv files with specific columns with specific values. Converting CRSDepTime into 24 hour time format. Solving and overcoming the technical issues with the sagemaker python code, especially the batch transform section. The Linear Learner model in sagemaker could not complete training because of the maximum 2 hour lab session, couldn't continue further with the Linear Learner deployment, batch transform and evaluating sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were the three most important things you learned about machine learning while completing this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using domain knowledge to determine that the weather and holidays might affect flights.\n",
    "- Can use PCA to reduce the number of columns in a dataset.\n",
    "- Metrics other than accuracy are important in understanding a model's performance such as Precision, Recall, F1-Score and the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
